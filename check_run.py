import torch
import sys
import os
import gdown
import zipfile

# Danh s√°ch model c·∫ßn t·∫£i
models = [
    {
        "name": "PassGPT",
        "url": "https://drive.google.com/uc?id=1tukK05TPl-1Qt7s33JTZ6F_JwqUvmh6m",
        "zip_path": "PassGPT/model_passgpt.zip",
        "extract_path": "PassGPT/model_passgpt",
        "required_files": ["model_passgpt"]
    },
    {
        "name": "PassGPTv2",
        "url": "https://drive.google.com/uc?id=1ZL7R0Ujf7jn_e_IUeViFpKhYYhfX3uBx",
        "zip_path": "PassGPTv2/model_passgptv2.zip",
        "extract_path": "PassGPTv2/model_passgptv2",
        "required_files": ["model_passgptv2"]
    }
]

def download_file(url, filename):
    print(f"üöÄ Downloading {filename} from Google Drive...")
    gdown.download(url, filename, quiet=False)

def extract_zip(zip_path, extract_to):
    print(f"üì¶ Extracting {zip_path} to {extract_to}...")
    # D√πng v·ªõi ZipFile ƒë·ªÉ gi·∫£i n√©n
    with zipfile.ZipFile(zip_path, 'r') as zObject:
        zObject.extractall(path=extract_to)
    print(f"‚úÖ Extracted to {extract_to}")

def check_required_files(base_path, required_files):
    for req in required_files:
        if not os.path.exists(os.path.join(base_path, req)):
            return False
    return True

def download_model():
    for model in models:
        # Ki·ªÉm tra n·∫øu th∆∞ m·ª•c model ƒë√£ t·ªìn t·∫°i v√† c√≥ ƒë·ªß file y√™u c·∫ßu
        if os.path.exists(model['extract_path']) and check_required_files(model['extract_path'], model['required_files']):
            print(f"‚úÖ Model '{model['name']}' already exists and is complete. Skipping download.\n")
            continue
        
        # N·∫øu ch∆∞a c√≥ th∆∞ m·ª•c ho·∫∑c thi·∫øu file y√™u c·∫ßu
        print(f"üöÄ Downloading model: {model['name']}")
        
        # N·∫øu ch∆∞a c√≥ file zip, t·∫£i v·ªÅ
        if not os.path.exists(model['zip_path']):
            download_file(model['url'], model['zip_path'])
        
        # Gi·∫£i n√©n n·∫øu th∆∞ m·ª•c ch∆∞a c√≥
        if not os.path.exists(model['extract_path']):
            extract_zip(model['zip_path'], model['extract_path'])
        
        # Kh√¥ng x√≥a file zip, v√¨ ch√∫ng ta kh√¥ng c·∫ßn x√≥a n√≥ n·ªØa
        print(f"üì¶ File zip '{model['zip_path']}' remains in place.\n")


# Ki·ªÉm tra GPU
if not torch.cuda.is_available():
    print("CUDA (GPU) kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra l·∫°i c√†i ƒë·∫∑t.")
    print("Tho√°t ch∆∞∆°ng tr√¨nh ...")
    sys.exit(1)  # Tho√°t ch∆∞∆°ng tr√¨nh v·ªõi m√£ l·ªói 1
else:
    print("CUDA (GPU) ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t.")
    if torch.cuda.is_available():
        print("T√™n GPU:", torch.cuda.get_device_name(0))
    download_model()

